{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All imports for this question\n",
    "# from google.colab import userdata\n",
    "import google.generativeai as genai\n",
    "from datasets import Dataset\n",
    "import random\n",
    "from typing import Callable, List, Any\n",
    "import json\n",
    "import requests\n",
    "import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "GEMINI_api_key = \"\"\n",
    "ChatGPT_key = \"\"\n",
    "Finhub_key = \"\"\n",
    "with open(r'../Keys/config.json') as config_file:\n",
    "    config = json.load(config_file)\n",
    "    GEMINI_api_key = config['Gemini_api_key']\n",
    "    ChatGPT_key = config['GPT_Key']\n",
    "    Finhub_key = config['Finhub_Key']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing Gemini API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagine you have a special friend, a computer, who can understand your words just like your mommy and daddy! That's what **Natural Language Processing** is all about. It's like teaching the computer how to speak and understand our language, English.\n",
      "\n",
      "It's like when you learn to read a book, you learn the words and how they fit together to make a story. The computer learns the words and how they fit together to understand what you're saying. Then, it can even answer you back in English!\n",
      "\n",
      "So, when you talk to a computer using **Natural Language Processing**, it's like having a fun conversation with your friend! You can ask it questions, tell it stories, and even play games. It's amazing! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "genai.configure(api_key=GEMINI_api_key)\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "# model = genai.GenerativeModel(\"gemini-1.0-pro\")\n",
    "response = model.generate_content(\"You are a financial analyst. Based on the data I am sharing with you, I need you to predict whether the value is going to increase or decrease\")\n",
    "print(response.text)\n",
    "# response = model.generate_content(\"Explain how AI works\")\n",
    "# print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing ChatGPT API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functions call themselves,  \n",
      "Echoing in endless loops,  \n",
      "Depths of code unfold.  \n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=ChatGPT_key)\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Write a haiku about recursion in programming.\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Code calls itself back,  \\nLayers of thought intertwine,  \\nEndless paths unfold.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))]\n"
     ]
    }
   ],
   "source": [
    "print(completion.choices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working on the context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GeminiCall(company, History = None, News = None ,Financial = None,Twitter = None):\n",
    "    context = \"You are a financial analyst. Analyze the following data and predict whether the stock price will increase or decrease:\\n\\n\"\n",
    "    data = f\"**Company:**{company} \\n**Historical Stock Price:**{History}\\n**Recent News:**{None}\\n**Financial Statements:**{Financial}\\n**Social Media Sentiment:**{Twitter}\"\n",
    "    prompt  = context + data + \"\\n\\n\\n Make the Prediction: (increase or decrease)\"\n",
    "    response = model.generate_text(prompt=prompt)\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GPTCall(prompt):\n",
    "    # prompt = f\"**Company:**{company} \\n**Historical Stock Price:**{History}\\n**Recent News:**{None}\\n**Financial Statements:**{Financial}\\n**Social Media Sentiment:**{Twitter}\"\n",
    "    # Maybe create a Prompt function\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a financial analyst. Analyze the following data and respond with only one word: either 'increase' or 'decrease' to indicate the stock price trend.:\\n\\n\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    prediction = response.choices[0].message.content.strip()\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(ticker, date_str, news_data, stock_data):\n",
    "    # prompt = f\"Please analyze the following data for {ticker} up to {date_str} and predict whether the stock price will go up or down:\\n\\n\"\n",
    "    # prompt = f\"**Company:**{ticker} \\n**Date of prediction:**{date_str} \\n**Historical Stock Price:**{History}\\n**Recent News:**{None}\\n**Financial Statements:**{Financial}\\n**Social Media Sentiment:**{Twitter}\"\n",
    "    prompt = f\"Company: {ticker}\\n Date of prediction: {date_str}\\n\"\n",
    "    prompt += \"Recent News Headlines:\\n\"\n",
    "    for news in news_data[:5]:  # Limit to first 5 news articles\n",
    "        prompt += f\"- {news['headline']}\\n\"\n",
    "\n",
    "    prompt += \"\\nStock Market Data (last 30 days):\\n\" # This is not correct right?\n",
    "    # Only select relevant columns\n",
    "    stock_info = stock_data[\n",
    "        [\"Date\", \"Stock Price\", \"High\", \"Low\", \"Close\", \"News Count\"]\n",
    "    ]\n",
    "    prompt += stock_info.to_string(index=False)\n",
    "\n",
    "    # We should include the twitter sentiment involved here\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:\n",
      "\n",
      "decrease\n"
     ]
    }
   ],
   "source": [
    "def get_company_news(ticker, from_date, to_date):\n",
    "    \"\"\"\n",
    "    Fetch news articles for a company from the Finnhub API.\n",
    "    \"\"\"\n",
    "    url = 'https://finnhub.io/api/v1/company-news'\n",
    "    params = {\n",
    "        'symbol': ticker,\n",
    "        'from': from_date,\n",
    "        'to': to_date,\n",
    "        'token': Finhub_key\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    data = response.json()\n",
    "    return data\n",
    "\n",
    "def prepare_data(ticker, date_str):\n",
    "    \"\"\"\n",
    "    Prepare news and stock data for the given company and date.\n",
    "    \"\"\"\n",
    "    # Parse date in DD/MM/YYYY format and reformat it to YYYY-MM-DD\n",
    "    date = datetime.datetime.strptime(date_str, '%d/%m/%Y')\n",
    "    from_date = (date - datetime.timedelta(days=30)).strftime('%Y-%m-%d')\n",
    "    to_date = date.strftime('%Y-%m-%d')\n",
    "    \n",
    "    news_data = get_company_news(ticker, from_date, to_date)\n",
    "    \n",
    "    stock_data = pd.read_csv(r'../Dataset/stock_data_august_2024.csv')\n",
    "    # Filter stock data for the company and last 30 days\n",
    "    stock_data['Date'] = pd.to_datetime(stock_data['Date'], dayfirst=True)\n",
    "\n",
    "    mask = (stock_data['Ticker'] == ticker) & (stock_data['Date'] >= from_date) & (stock_data['Date'] <= to_date)\n",
    "    company_stock_data = stock_data.loc[mask]\n",
    "    \n",
    "    return news_data, company_stock_data\n",
    "\n",
    "\n",
    "def main():\n",
    "    ticker = input(\"Input the company name:\")\n",
    "    date_str = input(\"Enter date in DD/MM/YYYY format:\")  # Example date in DD/MM/YYYY format\n",
    "    \n",
    "    # Prepare data\n",
    "    news_data, company_stock_data = prepare_data(\"MSFT\", \"10/10/2024\")\n",
    "    # print(news_data)\n",
    "    \n",
    "    # Create prompt\n",
    "    prompt = create_prompt(ticker, date_str, news_data, company_stock_data)\n",
    "    \n",
    "    # Get prediction\n",
    "    prediction = GPTCall(prompt)\n",
    "    \n",
    "    # Display the prediction\n",
    "    print(\"Prediction:\\n\")\n",
    "    print(prediction)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
